---
title: "Analisi Pinguini"
author: "Emanuel Michele Soda"
date: "11/27/2021"
output:
  html_document: 
    fig_width: 11
    fig_height: 10
    df_print: tibble
  pdf_document: default
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 80
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 12, 
                      fig.height = 8, warning=FALSE, 
                      set.seed (20211127))
library(tidyverse)
library(palmerpenguins)
library(tidymodels)
library(plotly)
library(factoextra)
library(sjPlot)
library(ggfortify)
library(dlookr)
theme_set(theme_light() + theme(legend.position = "bottom",
                                text = element_text(size=15)))
color_species <- c('#965F8A','#4AC6B7', "#C61951")
color_sex <- c('#d8b365','#7fbf7b')
```

# Exploratory data aalysis (EDA)

## Read data

First of all we will read the data. The data contains some NA values. So, we
will drop those NA values. After the drop of the NA values the dimension of the
tibble is $333 \times 8$.

```{r warning=FALSE}
penguins_df <- penguins %>% drop_na() 
penguins_df %>%  glimpse()
```

```{r}
penguins_df |> 
  count(species, sex) |> 
  mutate(perc = round(n /sum(n) * 100, 2)) |> 
  mutate(per = paste(perc, "%")) |> 
  ggplot(aes(sex, perc, fill = species,
             label = per)) +
  geom_col(position = 'fill') +
  geom_label(position = position_fill(vjust=0.5), size = 5)  +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = color_species)  +
  theme(legend.position = "top") +
  labs(x= NULL, y = "Percentage of species by sex")
```

## Number of penguin by species
We have three species of penguins:

-   **Adelie**
-   **Chinstrap**
-   **Gentoo**

As can be seen for the species we have unbalanced classes
```{r}
penguins_df %>%  
  count(species)  |> 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc))  |> 
  
  ggplot(aes(x = "", y = perc, fill = species)) +
  geom_col(color = "black") +
  geom_label(aes(label = labels), color = "white", size = 8,
             position = position_stack(vjust = 0.5),
             show.legend = FALSE) +
  coord_polar(theta = "y")  + 
  scale_fill_manual(values = color_species) +
  theme_void()
```

## Number of penguin by sex

As can be seen the number of male and female in the dataset is almost the same.
This is good because we do not have unbalanced classes.

```{r}
penguins_df %>%  
  count(sex) |> 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc)) |> 
  
  ggplot(aes(x = "", y = perc, fill = sex)) +
  geom_col(color = "black") +
  geom_label(aes(label = labels), color = "white", size = 8,
             position = position_stack(vjust = 0.5),
             show.legend = FALSE) +
  coord_polar(theta = "y")  + 
  scale_fill_manual(values = color_sex) +
  theme_void()
```

## dlooker package

A very good package for EDA is dlooker. Let's use some of its function to
analyze our dataset. As can be seen the percentage of missing data is not
drammatic. We could think of imputing them.

```{r}
plot_na_pareto(penguins, only_na = T) + 
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5))
```

Fortunately dlooker is able also to impute the missing data using different
approches:

-   mean
-   rpart: Recursive Paritioning and Regression Trees
-   mice: Multivariate Inputation by Chained Equations

```{r}
penguins_impute <- penguins  %>% 
  mutate(imputate_na(.data = penguins, 
            xvar = bill_depth_mm, 
            yvar = sex, method = "mean", no_attrs = T,
            print_flag = T))

```

## Plot variance feature

```{r}
my_comparisons <- list(c("female", "male"))
penguins_df  %>% 
  select(-c(island, year)) %>%  
  pivot_longer(bill_length_mm:body_mass_g) %>%
  mutate(across(where(is_character), as_factor)) %>% 
  
  ggplot(., aes(sex, value, fill = sex, color = species)) +
  geom_violin(width=0.7, color = "black", alpha = 0.3) +
  geom_jitter(width=0.25, alpha = 0.8) +
  geom_boxplot(width= 0.09, fill = "white", color = "black", alpha = 0.3) +
  scale_y_log10() +
  scale_fill_manual(values = color_sex) + 
  scale_color_manual(values = color_species) +
  labs(col = "Species", fill = "Sex", size = "Size", x = NULL, y = NULL) +
  ggpubr::stat_compare_means(comparisons = my_comparisons, 
                             label = "p.signif") +
  facet_wrap("name", scales = "free") +
  scale_size(range = c(1, 3)) +
  theme(legend.position="right") 


penguins_df  %>% 
  select(-c(island, year)) %>%  
  pivot_longer(bill_length_mm:body_mass_g) %>% 
  mutate(across(where(is_character), as_factor)) %>% 
  
  ggplot(., aes(value, fill = sex)) +
  geom_density(alpha= 0.3) +
  labs(x = NULL) +
  scale_fill_manual(values = color_sex)  +
  facet_wrap("name", scales = "free") 
```

```{r}
ggstatsplot::ggcorrmat(
  data     = penguins_df  %>% select(-c(island, year, species, sex)),
  colors   = c("#B2182B", "white", "#4D4D4D"),
  title    = "Correlation among predictors",
  matrix.type  = "lower")
```

## Plot in a 3D space using the predictor

Let's make a scatterplot using three predictors which are:

-   **bill_length_mm**
-   **bill_depth_mm**
-   **flipper_length_mm**

The size of the dot will be scaled by **body_mass_g** and we will color the dots
by sex

```{r}
plot_ly(penguins_df, x = ~bill_length_mm, y = ~bill_depth_mm, 
        z = ~flipper_length_mm, size = ~body_mass_g,
        marker = list(symbol = 'circle', 
                      sizemode = 'diameter'), 
        sizes = c(1, 20),
        color = ~sex, colors = color_sex)
```

Let's do the same for the **species**

```{r}
plot_ly(penguins_df, x = ~bill_length_mm, y = ~bill_depth_mm, 
        z = ~flipper_length_mm, size = ~body_mass_g,
        marker = list(symbol = 'circle', 
                      sizemode = 'diameter'), 
        sizes = c(1, 20),
        color = ~species, colors = color_species)

penguins_df %>% 
ggplot(., aes(x = bill_length_mm, y = bill_depth_mm, 
              col = sex, shape = island, size = body_mass_g)) +
  geom_point(alpha = 0.7)  +
  scale_color_manual(values = c('#965F8A','#4AC6B7')) +
  theme(legend.position = "top") +
  facet_wrap("species")  
```

## PCA Plot

```{r}
pca_trans <- penguins_df |>  
  recipe(~., penguins_df) |> 
  update_role(species, island, year, sex, new_role = "id") %>%
  step_center(all_numeric_predictors()) |>  
  step_scale(all_numeric_predictors()) |> 
  step_pca(all_numeric_predictors(), num_comp = 5, keep_original_cols = T)

pca_estimates <- prep(pca_trans, training = 
                        penguins_df, retain = T,verbose = T)

pca_estimates |> 
  juice() |>  
  
  ggplot(aes(PC1, PC2, fill= sex, size = body_mass_g)) +
  geom_point(shape = 21, col = "black") +
  labs(size = "body mass") +
  scale_fill_manual(values = color_sex)
```

## Percentage variance Expressed by PCs

First of all we will have a look to the percentage of expressed variance by each
of the PC. As can be seen the cumulativepercentage of expressed variance by the
first two is about $80\%$.

```{r}
pca_res <- prcomp(penguins_df %>% select(-c(species, island, year, sex)), 
                  scale. = TRUE) 

fviz_eig(pca_res, barcolor = "black", 
         main = NULL, ylab = "Percentage explained variance") +
   scale_y_continuous(labels = ~paste0(.x , '%'))

get_eig(pca_res) %>% data.frame() %>% 
  rownames_to_column("Dimensions")  %>% 
  mutate(across(where(is_character), as_factor)) %>% 
  mutate(Dimensions = str_remove(string = Dimensions,pattern = "Dim.")) %>% 
  ggplot(., aes(Dimensions, cumulative.variance.percent)) +
  geom_bar(stat="identity", fill="steelblue", col = "black") +
  geom_line(aes(group=1))  +
  geom_point() +
  scale_y_continuous(labels = ~paste0(.x , '%')) +
  labs(y= "Cumulative percentage explained variance")

```

## PCA plot by sex

```{r}
pca_dat <- pca_estimates |> juice()

plot_ly(pca_dat, x = ~PC1, y = ~PC2, z = ~PC3,
        color = ~sex, colors = color_sex)
```

## PCA plot by species

```{r}
plot_ly(pca_dat, x = ~PC1, y = ~PC2, z = ~PC3,
        color = ~species, colors = color_species)
```

# Creation of the model to predict the sex

As we have seen from the plot the data cluster very well according to the three
species, this because of course the three species are based on those
measurements. For this reason we will try to predict the sex based on those
measurements.

First of all we have to create the training dataset that we will call
**penguin_train**. Unfortunately the entire dataset has only 333 sample. Those
are not a lot for those reason order to improve the performance we will use the
resampling.

The dimension of the training is 249 and for the test we have 84.

```{r}
penguins_df <- penguins_df %>% select(- c(year, island, species))
# Creation of a split stratified by sex in order to have the same number 
# of observation in each group 
penguin_split <- initial_split(penguins_df, strata = sex)

penguin_train <- training(penguin_split)
penguin_test <- testing(penguin_split)
```

# Creating the model

We will use two very simple model **logistic regression** and a more complex but
less interpretable model **random forest**

```{r}
glm_spec <- logistic_reg() %>%
  set_engine("glm")

rf_spec <- rand_forest() %>%
  set_mode("classification") %>%
  set_engine("ranger")

# In order to fit the model we need to  create a workflow so
# We will predict sex based on all the other predictor 
# bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
penguin_wf <- workflow() %>%
  add_formula(sex ~ .)
```

# Fit the model

## Creting the resampling dataset

```{r}
folds <- vfold_cv(data = penguin_train, v = 10, 
                  repeats = 100, strata = sex)
folds
```

## Fitting the model

```{r}
start_time <- Sys.time()

doParallel::registerDoParallel(cores = 8) 

# Logistic model
pengun_logistic <-
  penguin_wf %>% 
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = folds,
    control = control_resamples(save_pred = T, verbose = T))

end_time <- Sys.time()
# Random Forest model 
pengun_random_forest <-
  penguin_wf %>% 
  add_model(rf_spec) %>%
  fit_resamples(
    resamples = folds,
    control = control_resamples(save_pred = T, verbose = T))
```

# Metrics

## Accuracy and AUC

As can be seen even if the \_\_Random Forest\_ is more complex model as can be
seen the **Logistic Regression** have similar performance. For this reason we
will use the **Logistic Regression** because is a lot simpler to interpret.

```{r}
collect_metrics(pengun_logistic)

collect_metrics(pengun_random_forest)
```

# ROC curve

As can be see the ROC Curve for each resample is quite good

```{r}
pengun_logistic %>%
  collect_predictions() %>%
  group_by(id) %>%
  roc_curve(sex, .pred_female) %>%
  ggplot(aes(1 - specificity, sensitivity, color = id)) +
  geom_abline(lty = 2, color = "gray60") +
  geom_path() +
  theme(legend.position = "bottom") +
  scale_color_brewer(palette = "Set3") +
  coord_equal()
```

## Confusion Matrix

And also the Confusion matrix is quite good

```{r}
penguin_final <- penguin_wf %>%
  add_model(glm_spec) %>%
  last_fit(penguin_split)

collect_predictions(penguin_final) %>%
  conf_mat(sex, .pred_class) %>% 
  autoplot(type = "heatmap") 
```

# Interpretation

The use of a **logistic regression** is good because is a very simple and so
very interpretable model. In particular there is a property for which the if the
exponentiate parameter of the model corresponds to the odds ration

```{r}
penguin_final$.workflow[[1]] %>%
  tidy(exponentiate = TRUE)  %>% 
  mutate(p.value = round(p.value, 10)) %>% 
  mutate(estimate = round(estimate, 5))
```

For this reason we can say that for each $1$ mm increment in the
\_\_bill_depth_mm\_\_the odds of beeing male vs beeing female increase of $7.23$
time.

```{r}
m1 <- stats::glm(formula = sex ~., family =  stats::binomial, penguin_train)

summary(m1)
```

```{r}
plot_model(m1, sort.est = TRUE,show.values = T)
```

Last we plot the model parameter for the predictor

```{r}
ggstatsplot::ggcoefstats(m1, ggtheme = theme_light())
```

As can be seen the **flipper_length_mm** and the \_\_bill_length_mm\_ are not
statistically significant. We can remove those predictors and train again the
model.

```{r}
penguin_train <- 
  penguin_train %>%  
  select(- c(flipper_length_mm, bill_length_mm))

m2 <- stats::glm(formula = sex ~., family =  stats::binomial, penguin_train)
summary(m2)
```

Looking at the final model we can say that for each $1$ mm increment in the
**bill_depth_mm** the odds of beeing male vs beeing female increase of $7.45$
time. While for each $1$ g increment in the **bill_depth_mm** the odds of beeing
male vs beeing female increase of $1.01$ times.

```{r}
plot_model(m2, sort.est = TRUE, show.values = T)
```

```{r}
ggstatsplot::ggcoefstats(m2, ggtheme = theme_light())
```

As can be seen from the pie chart almost 90.5% of the prediction were good

```{r}
class_label_test <-  penguin_test %>% pull(sex)
penguin_test <- penguin_test %>% select(-c(flipper_length_mm, sex))
predicted_porb <-
  m2 %>% 
  predict(penguin_test, type = "response") 

predicted_sex <-
ifelse(test = predicted_porb > 0.4, yes = "male", "female")

penguin_test %>% 
  mutate(sex_true = class_label_test,
         sex_predicted = predicted_sex) %>% 
  mutate(good = ifelse(test = sex_true != sex_predicted, 
                       "Not correct", "Correct")) %>% 
  count(good) %>% 
  
  ggplot(., aes(x="", y=n, fill=good)) +
  geom_bar(width = 1, stat = "identity", col = "white") +
  geom_label(aes(label = paste0(round(n/sum(n)*100, 1), "%")),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +  
  theme_void() +
  labs(fill= "The prediction is correct?") +
  theme(axis.text.x=element_blank()) + 
  scale_fill_manual(values = c('#2c7fb8','#f03b20'))  
```
